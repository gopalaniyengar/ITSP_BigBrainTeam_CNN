{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ITSP Proj MK2 Part 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15frB_Q0uITj4G6k_hNX6ekLUdLDbqLLR",
      "authorship_tag": "ABX9TyMC8lSPizbooVLbuqk8M0Ny",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gopalaniyengar/ITSP_BigBrainTeam_CNN/blob/Gopalan/ITSP_Proj_MK2_Part_2w/plots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdXpKUd26lyn",
        "colab_type": "code",
        "outputId": "20e4c9c7-aef1-498d-8e74-475d06abc0aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "/pwd\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TKal2XY4cFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64tZpj-o4dn5",
        "colab_type": "code",
        "outputId": "a95a0cb1-5213-4654-964e-9719aad831d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "transform=transforms.ToTensor()\n",
        "trainset=datasets.EMNIST(root='/content/drive/My Drive/Colab Notebooks/data', split= 'byclass', train=True, download=True, transform=transform)\n",
        "testset=datasets.EMNIST(root='/content/drive/My Drive/Colab Notebooks/data', split= 'byclass', train=False, download=True, transform=transform)\n",
        "print(len(trainset))\n",
        "print(len(testset))\n",
        "print(len(trainset)+len(testset))\n",
        "print(1)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "697932\n",
            "116323\n",
            "814255\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hePOsjPz4dw-",
        "colab_type": "code",
        "outputId": "9aa5a414-3881-4716-be4e-ce7b5339979a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "batch=32\n",
        "numberofbatches=697932/32\n",
        "print(numberofbatches)\n",
        "numberofbatches=21811\n",
        "print(numberofbatches)\n",
        "trainloadeddata=DataLoader(trainset, batch_size=batch, shuffle= True)\n",
        "testloadeddata=DataLoader(testset, batch_size=batch, shuffle= True)\n",
        "#for batchno,(image, labels) in enumerate(trainloadeddata):\n",
        "    #if  batchno==1:\n",
        "     #print(image, labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21810.375\n",
            "21811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s20oeBYZ4d4P",
        "colab_type": "code",
        "outputId": "35660064-fec1-499b-c445-7488d9f94d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class ModelOfNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelOfNet,self).__init__()\n",
        "\n",
        "        self.convolve=nn.Sequential(\n",
        "                nn.Conv2d(1,8,3,1,1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(8,16,3,1,1),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(16),\n",
        "                nn.MaxPool2d(2,2),\n",
        "                nn.Conv2d(16,32,3,1,1),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(32),\n",
        "                nn.MaxPool2d(2,2),\n",
        "        )\n",
        "        self.fullyconnect=nn.Linear(1568,62)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x=self.convolve(x)\n",
        "        x=x.view(x.size(0),-1)\n",
        "        x=self.fullyconnect(x)\n",
        "        return x \n",
        "    print('I sure hope this model works fine this time without any errors')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I sure hope this model works fine this time without any errors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TgItzMg4d5e",
        "colab_type": "code",
        "outputId": "ad710f4f-ba08-47f7-b2ca-bfc1edf8095a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "MYNN=ModelOfNet()\n",
        "print(MYNN)\n",
        "classwts=torch.load('/content/drive/My Drive/Colab Notebooks/lossweights.pt')\n",
        "print(classwts)\n",
        "print(classwts.dtype)\n",
        "lossfunction=torch.nn.CrossEntropyLoss(weight=classwts)\n",
        "updatefunction=torch.optim.Adam(MYNN.parameters(), lr=0.00001)\n",
        "print('completed running block')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ModelOfNet(\n",
            "  (convolve): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU()\n",
            "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fullyconnect): Linear(in_features=1568, out_features=62, bias=True)\n",
            ")\n",
            "tensor([0.3255, 0.2933, 0.3291, 0.3203, 0.3357, 0.3583, 0.3288, 0.3148, 0.3316,\n",
            "        0.3326, 1.7570, 2.9028, 1.1152, 2.4676, 2.2815, 1.2260, 4.4724, 3.5714,\n",
            "        0.9423, 2.9923, 4.5612, 2.2177, 1.2505, 1.3666, 0.4506, 1.3486, 4.3213,\n",
            "        2.2190, 0.5421, 1.1463, 0.8933, 2.4276, 2.3977, 4.0624, 2.3734, 4.1677,\n",
            "        1.1220, 2.1820, 3.9443, 1.1061, 0.4570, 4.3955, 3.0532, 1.2883, 4.1310,\n",
            "        5.9372, 4.5191, 0.7349, 4.2559, 0.9859, 4.0949, 4.5984, 3.7598, 0.7981,\n",
            "        4.1708, 0.6164, 3.9777, 3.8684, 4.1739, 3.9890, 4.7598, 4.1310])\n",
            "torch.float32\n",
            "completed running block\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzknQT-z4dwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validationtrainingtime(epochs):\n",
        "  avglossoverepochs=[]\n",
        "  accuracyoverepochs=[]\n",
        "  validationaccuracyoverepochs=[]\n",
        "  for i in range(epochs):\n",
        "    sum=0.0\n",
        "    avgaccuracyoverepoch=0.0\n",
        "    sumbatch=0.0\n",
        "    for batchno,(image, labels) in enumerate(trainloadeddata):\n",
        "\n",
        "      updatefunction.zero_grad()\n",
        "      resultofmodel=MYNN(image)\n",
        "      losscalc=lossfunction(resultofmodel, labels)\n",
        "      resultofmodel=F.softmax(resultofmodel, dim=1)\n",
        "      #print(resultofmodel.shape)\n",
        "      pred=torch.argmax(resultofmodel, dim=1)\n",
        "      #print(pred)\n",
        "      \n",
        "      count=0.0\n",
        "      assert pred.shape[0]==labels.shape[0]\n",
        "      for j in range(pred.shape[0]):\n",
        "        if pred[j]==labels[j]:\n",
        "          count=count+1.0\n",
        "      \n",
        "      batchaccuracy=(count/pred.shape[0])*100\n",
        "      sum=sum+losscalc\n",
        "      sumbatch=sumbatch+losscalc\n",
        "      losscalc.backward()\n",
        "      updatefunction.step()\n",
        "\n",
        "      if batchno%1000==True:\n",
        "        print(i, batchno, \"Batch Loss:\", losscalc,\"Batch Accuracy=\", batchaccuracy,\"%\", \"Average Loss Over 1000 Batches:\", (sumbatch/1000))\n",
        "        sumbatch=0.0\n",
        "      avgaccuracyoverepoch=avgaccuracyoverepoch+(batchaccuracy/numberofbatches)\n",
        "      if batchno==17500:\n",
        "        break\n",
        "\n",
        "    print(\"Average Loss over Epoch:\", (sum/numberofbatches))\n",
        "    print(\"Average Accuracy over Epoch:\", avgaccuracyoverepoch, \"%\")\n",
        "    accuracyoverepochs.append(avgaccuracyoverepoch)\n",
        "    avglossoverepochs.append((sum/numberofbatches))\n",
        "    avgvalidationaccuracyoverepoch=0.0\n",
        "    for batchno2,(image2,labels2) in enumerate(trainloadeddata):\n",
        "      if batchno2>17500:  \n",
        "        with torch.no_grad():\n",
        "            resultofmodel2=MYNN(image2)\n",
        "            losscalc2=lossfunction(resultofmodel2, labels2)\n",
        "            resultofmodel2=F.softmax(resultofmodel2, dim=1)\n",
        "            #print(resultofmodel2.shape)\n",
        "            pred2=torch.argmax(resultofmodel2, dim=1)\n",
        "            #print(pred2)\n",
        "            \n",
        "            count2=0.0\n",
        "            assert pred2.shape[0]==labels2.shape[0]\n",
        "            for k in range(pred2.shape[0]):\n",
        "              if pred2[k]==labels2[k]:\n",
        "                count2=count2+1.0\n",
        "            batchaccuracy2=(count2/pred2.shape[0])*100\n",
        "\n",
        "            if batchno2%100==True:\n",
        "              print(i, batchno2, \"Batch Validation Accuracy=\", batchaccuracy2, \"%\")\n",
        "            avgvalidationaccuracyoverepoch=avgvalidationaccuracyoverepoch+(batchaccuracy2/(numberofbatches-17500))\n",
        "\n",
        "    print(\"Average Validation Accuracy over Epoch=\", avgvalidationaccuracyoverepoch)\n",
        "    validationaccuracyoverepochs.append(avgvalidationaccuracyoverepoch)  \n",
        "  print('hopefully i reach this part of the function')\n",
        "  print(accuracyoverepochs)\n",
        "  print(avglossoverepochs)\n",
        "  print(validationaccuracyoverepochs) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH3a4MXt4dnG",
        "colab_type": "code",
        "outputId": "2a056065-49fe-4dd5-c8bf-5b53fbc6a308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epoch=10\n",
        "validationtrainingtime(epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1 Batch Loss: tensor(4.6991, grad_fn=<NllLossBackward>) Batch Accuracy= 6.25 % Average Loss Over 1000 Batches: tensor(0.0091, grad_fn=<DivBackward0>)\n",
            "0 1001 Batch Loss: tensor(2.8916, grad_fn=<NllLossBackward>) Batch Accuracy= 56.25 % Average Loss Over 1000 Batches: tensor(3.6417, grad_fn=<DivBackward0>)\n",
            "0 2001 Batch Loss: tensor(2.3244, grad_fn=<NllLossBackward>) Batch Accuracy= 40.625 % Average Loss Over 1000 Batches: tensor(2.6394, grad_fn=<DivBackward0>)\n",
            "0 3001 Batch Loss: tensor(1.5741, grad_fn=<NllLossBackward>) Batch Accuracy= 65.625 % Average Loss Over 1000 Batches: tensor(2.1155, grad_fn=<DivBackward0>)\n",
            "0 4001 Batch Loss: tensor(1.9647, grad_fn=<NllLossBackward>) Batch Accuracy= 56.25 % Average Loss Over 1000 Batches: tensor(1.8505, grad_fn=<DivBackward0>)\n",
            "0 5001 Batch Loss: tensor(1.6776, grad_fn=<NllLossBackward>) Batch Accuracy= 56.25 % Average Loss Over 1000 Batches: tensor(1.6322, grad_fn=<DivBackward0>)\n",
            "0 6001 Batch Loss: tensor(1.3298, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(1.5195, grad_fn=<DivBackward0>)\n",
            "0 7001 Batch Loss: tensor(1.6312, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(1.4206, grad_fn=<DivBackward0>)\n",
            "0 8001 Batch Loss: tensor(1.1469, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(1.3404, grad_fn=<DivBackward0>)\n",
            "0 9001 Batch Loss: tensor(0.6491, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(1.2845, grad_fn=<DivBackward0>)\n",
            "0 10001 Batch Loss: tensor(1.2477, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(1.2567, grad_fn=<DivBackward0>)\n",
            "0 11001 Batch Loss: tensor(2.2674, grad_fn=<NllLossBackward>) Batch Accuracy= 65.625 % Average Loss Over 1000 Batches: tensor(1.1924, grad_fn=<DivBackward0>)\n",
            "0 12001 Batch Loss: tensor(1.1906, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(1.1376, grad_fn=<DivBackward0>)\n",
            "0 13001 Batch Loss: tensor(1.5307, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(1.1025, grad_fn=<DivBackward0>)\n",
            "0 14001 Batch Loss: tensor(1.7150, grad_fn=<NllLossBackward>) Batch Accuracy= 68.75 % Average Loss Over 1000 Batches: tensor(1.0862, grad_fn=<DivBackward0>)\n",
            "0 15001 Batch Loss: tensor(1.1417, grad_fn=<NllLossBackward>) Batch Accuracy= 56.25 % Average Loss Over 1000 Batches: tensor(1.0545, grad_fn=<DivBackward0>)\n",
            "0 16001 Batch Loss: tensor(1.1461, grad_fn=<NllLossBackward>) Batch Accuracy= 68.75 % Average Loss Over 1000 Batches: tensor(1.0136, grad_fn=<DivBackward0>)\n",
            "0 17001 Batch Loss: tensor(0.8992, grad_fn=<NllLossBackward>) Batch Accuracy= 62.5 % Average Loss Over 1000 Batches: tensor(1.0240, grad_fn=<DivBackward0>)\n",
            "Average Loss over Epoch: tensor(1.2302, grad_fn=<DivBackward0>)\n",
            "Average Accuracy over Epoch: 52.014321901782026 %\n",
            "0 17501 Batch Validation Accuracy= 71.875 %\n",
            "0 17601 Batch Validation Accuracy= 68.75 %\n",
            "0 17701 Batch Validation Accuracy= 87.5 %\n",
            "0 17801 Batch Validation Accuracy= 78.125 %\n",
            "0 17901 Batch Validation Accuracy= 78.125 %\n",
            "0 18001 Batch Validation Accuracy= 71.875 %\n",
            "0 18101 Batch Validation Accuracy= 75.0 %\n",
            "0 18201 Batch Validation Accuracy= 78.125 %\n",
            "0 18301 Batch Validation Accuracy= 71.875 %\n",
            "0 18401 Batch Validation Accuracy= 78.125 %\n",
            "0 18501 Batch Validation Accuracy= 68.75 %\n",
            "0 18601 Batch Validation Accuracy= 71.875 %\n",
            "0 18701 Batch Validation Accuracy= 75.0 %\n",
            "0 18801 Batch Validation Accuracy= 75.0 %\n",
            "0 18901 Batch Validation Accuracy= 71.875 %\n",
            "0 19001 Batch Validation Accuracy= 59.375 %\n",
            "0 19101 Batch Validation Accuracy= 78.125 %\n",
            "0 19201 Batch Validation Accuracy= 68.75 %\n",
            "0 19301 Batch Validation Accuracy= 59.375 %\n",
            "0 19401 Batch Validation Accuracy= 65.625 %\n",
            "0 19501 Batch Validation Accuracy= 78.125 %\n",
            "0 19601 Batch Validation Accuracy= 81.25 %\n",
            "0 19701 Batch Validation Accuracy= 71.875 %\n",
            "0 19801 Batch Validation Accuracy= 65.625 %\n",
            "0 19901 Batch Validation Accuracy= 84.375 %\n",
            "0 20001 Batch Validation Accuracy= 68.75 %\n",
            "0 20101 Batch Validation Accuracy= 68.75 %\n",
            "0 20201 Batch Validation Accuracy= 62.5 %\n",
            "0 20301 Batch Validation Accuracy= 78.125 %\n",
            "0 20401 Batch Validation Accuracy= 75.0 %\n",
            "0 20501 Batch Validation Accuracy= 78.125 %\n",
            "0 20601 Batch Validation Accuracy= 65.625 %\n",
            "0 20701 Batch Validation Accuracy= 81.25 %\n",
            "0 20801 Batch Validation Accuracy= 84.375 %\n",
            "0 20901 Batch Validation Accuracy= 71.875 %\n",
            "0 21001 Batch Validation Accuracy= 71.875 %\n",
            "0 21101 Batch Validation Accuracy= 87.5 %\n",
            "0 21201 Batch Validation Accuracy= 81.25 %\n",
            "0 21301 Batch Validation Accuracy= 75.0 %\n",
            "0 21401 Batch Validation Accuracy= 71.875 %\n",
            "0 21501 Batch Validation Accuracy= 75.0 %\n",
            "0 21601 Batch Validation Accuracy= 59.375 %\n",
            "0 21701 Batch Validation Accuracy= 68.75 %\n",
            "0 21801 Batch Validation Accuracy= 75.0 %\n",
            "Average Validation Accuracy over Epoch= 71.7781063944944\n",
            "1 1 Batch Loss: tensor(1.0532, grad_fn=<NllLossBackward>) Batch Accuracy= 46.875 % Average Loss Over 1000 Batches: tensor(0.0016, grad_fn=<DivBackward0>)\n",
            "1 1001 Batch Loss: tensor(1.0449, grad_fn=<NllLossBackward>) Batch Accuracy= 65.625 % Average Loss Over 1000 Batches: tensor(0.9830, grad_fn=<DivBackward0>)\n",
            "1 2001 Batch Loss: tensor(0.5113, grad_fn=<NllLossBackward>) Batch Accuracy= 90.625 % Average Loss Over 1000 Batches: tensor(0.9624, grad_fn=<DivBackward0>)\n",
            "1 3001 Batch Loss: tensor(0.8786, grad_fn=<NllLossBackward>) Batch Accuracy= 68.75 % Average Loss Over 1000 Batches: tensor(0.9695, grad_fn=<DivBackward0>)\n",
            "1 4001 Batch Loss: tensor(1.8853, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.9541, grad_fn=<DivBackward0>)\n",
            "1 5001 Batch Loss: tensor(0.4442, grad_fn=<NllLossBackward>) Batch Accuracy= 90.625 % Average Loss Over 1000 Batches: tensor(0.9266, grad_fn=<DivBackward0>)\n",
            "1 6001 Batch Loss: tensor(1.5892, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.9286, grad_fn=<DivBackward0>)\n",
            "1 7001 Batch Loss: tensor(0.7111, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.9208, grad_fn=<DivBackward0>)\n",
            "1 8001 Batch Loss: tensor(0.7404, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.8853, grad_fn=<DivBackward0>)\n",
            "1 9001 Batch Loss: tensor(0.7586, grad_fn=<NllLossBackward>) Batch Accuracy= 65.625 % Average Loss Over 1000 Batches: tensor(0.9236, grad_fn=<DivBackward0>)\n",
            "1 10001 Batch Loss: tensor(1.5703, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.8837, grad_fn=<DivBackward0>)\n",
            "1 11001 Batch Loss: tensor(0.7281, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.8740, grad_fn=<DivBackward0>)\n",
            "1 12001 Batch Loss: tensor(0.7603, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.8719, grad_fn=<DivBackward0>)\n",
            "1 13001 Batch Loss: tensor(0.4965, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.8412, grad_fn=<DivBackward0>)\n",
            "1 14001 Batch Loss: tensor(1.5063, grad_fn=<NllLossBackward>) Batch Accuracy= 68.75 % Average Loss Over 1000 Batches: tensor(0.8587, grad_fn=<DivBackward0>)\n",
            "1 15001 Batch Loss: tensor(0.7284, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.8472, grad_fn=<DivBackward0>)\n",
            "1 16001 Batch Loss: tensor(1.9069, grad_fn=<NllLossBackward>) Batch Accuracy= 59.375 % Average Loss Over 1000 Batches: tensor(0.8157, grad_fn=<DivBackward0>)\n",
            "1 17001 Batch Loss: tensor(1.0655, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.8455, grad_fn=<DivBackward0>)\n",
            "Average Loss over Epoch: tensor(0.7196, grad_fn=<DivBackward0>)\n",
            "Average Accuracy over Epoch: 59.48618243086869 %\n",
            "1 17501 Batch Validation Accuracy= 65.625 %\n",
            "1 17601 Batch Validation Accuracy= 65.625 %\n",
            "1 17701 Batch Validation Accuracy= 65.625 %\n",
            "1 17801 Batch Validation Accuracy= 65.625 %\n",
            "1 17901 Batch Validation Accuracy= 93.75 %\n",
            "1 18001 Batch Validation Accuracy= 81.25 %\n",
            "1 18101 Batch Validation Accuracy= 68.75 %\n",
            "1 18201 Batch Validation Accuracy= 93.75 %\n",
            "1 18301 Batch Validation Accuracy= 65.625 %\n",
            "1 18401 Batch Validation Accuracy= 84.375 %\n",
            "1 18501 Batch Validation Accuracy= 68.75 %\n",
            "1 18601 Batch Validation Accuracy= 71.875 %\n",
            "1 18701 Batch Validation Accuracy= 68.75 %\n",
            "1 18801 Batch Validation Accuracy= 84.375 %\n",
            "1 18901 Batch Validation Accuracy= 78.125 %\n",
            "1 19001 Batch Validation Accuracy= 81.25 %\n",
            "1 19101 Batch Validation Accuracy= 68.75 %\n",
            "1 19201 Batch Validation Accuracy= 78.125 %\n",
            "1 19301 Batch Validation Accuracy= 68.75 %\n",
            "1 19401 Batch Validation Accuracy= 75.0 %\n",
            "1 19501 Batch Validation Accuracy= 62.5 %\n",
            "1 19601 Batch Validation Accuracy= 71.875 %\n",
            "1 19701 Batch Validation Accuracy= 71.875 %\n",
            "1 19801 Batch Validation Accuracy= 68.75 %\n",
            "1 19901 Batch Validation Accuracy= 68.75 %\n",
            "1 20001 Batch Validation Accuracy= 56.25 %\n",
            "1 20101 Batch Validation Accuracy= 84.375 %\n",
            "1 20201 Batch Validation Accuracy= 81.25 %\n",
            "1 20301 Batch Validation Accuracy= 65.625 %\n",
            "1 20401 Batch Validation Accuracy= 65.625 %\n",
            "1 20501 Batch Validation Accuracy= 68.75 %\n",
            "1 20601 Batch Validation Accuracy= 81.25 %\n",
            "1 20701 Batch Validation Accuracy= 84.375 %\n",
            "1 20801 Batch Validation Accuracy= 81.25 %\n",
            "1 20901 Batch Validation Accuracy= 84.375 %\n",
            "1 21001 Batch Validation Accuracy= 81.25 %\n",
            "1 21101 Batch Validation Accuracy= 71.875 %\n",
            "1 21201 Batch Validation Accuracy= 71.875 %\n",
            "1 21301 Batch Validation Accuracy= 78.125 %\n",
            "1 21401 Batch Validation Accuracy= 71.875 %\n",
            "1 21501 Batch Validation Accuracy= 68.75 %\n",
            "1 21601 Batch Validation Accuracy= 68.75 %\n",
            "1 21701 Batch Validation Accuracy= 81.25 %\n",
            "1 21801 Batch Validation Accuracy= 68.75 %\n",
            "Average Validation Accuracy over Epoch= 75.19982795948391\n",
            "2 1 Batch Loss: tensor(1.0338, grad_fn=<NllLossBackward>) Batch Accuracy= 56.25 % Average Loss Over 1000 Batches: tensor(0.0018, grad_fn=<DivBackward0>)\n",
            "2 1001 Batch Loss: tensor(1.9532, grad_fn=<NllLossBackward>) Batch Accuracy= 68.75 % Average Loss Over 1000 Batches: tensor(0.8210, grad_fn=<DivBackward0>)\n",
            "2 2001 Batch Loss: tensor(0.4327, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.8242, grad_fn=<DivBackward0>)\n",
            "2 3001 Batch Loss: tensor(0.9250, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.8150, grad_fn=<DivBackward0>)\n",
            "2 4001 Batch Loss: tensor(1.0049, grad_fn=<NllLossBackward>) Batch Accuracy= 59.375 % Average Loss Over 1000 Batches: tensor(0.8052, grad_fn=<DivBackward0>)\n",
            "2 5001 Batch Loss: tensor(0.7285, grad_fn=<NllLossBackward>) Batch Accuracy= 68.75 % Average Loss Over 1000 Batches: tensor(0.7878, grad_fn=<DivBackward0>)\n",
            "2 6001 Batch Loss: tensor(0.6913, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.7829, grad_fn=<DivBackward0>)\n",
            "2 7001 Batch Loss: tensor(0.4091, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.7930, grad_fn=<DivBackward0>)\n",
            "2 8001 Batch Loss: tensor(0.5590, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.7916, grad_fn=<DivBackward0>)\n",
            "2 9001 Batch Loss: tensor(0.6413, grad_fn=<NllLossBackward>) Batch Accuracy= 65.625 % Average Loss Over 1000 Batches: tensor(0.7891, grad_fn=<DivBackward0>)\n",
            "2 10001 Batch Loss: tensor(0.8451, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.7681, grad_fn=<DivBackward0>)\n",
            "2 11001 Batch Loss: tensor(0.9303, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.7607, grad_fn=<DivBackward0>)\n",
            "2 12001 Batch Loss: tensor(0.7160, grad_fn=<NllLossBackward>) Batch Accuracy= 65.625 % Average Loss Over 1000 Batches: tensor(0.7755, grad_fn=<DivBackward0>)\n",
            "2 13001 Batch Loss: tensor(0.6812, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.7862, grad_fn=<DivBackward0>)\n",
            "2 14001 Batch Loss: tensor(0.4799, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.7677, grad_fn=<DivBackward0>)\n",
            "2 15001 Batch Loss: tensor(0.5769, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.7662, grad_fn=<DivBackward0>)\n",
            "2 16001 Batch Loss: tensor(0.4371, grad_fn=<NllLossBackward>) Batch Accuracy= 87.5 % Average Loss Over 1000 Batches: tensor(0.7609, grad_fn=<DivBackward0>)\n",
            "2 17001 Batch Loss: tensor(0.4257, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.7505, grad_fn=<DivBackward0>)\n",
            "Average Loss over Epoch: tensor(0.6291, grad_fn=<DivBackward0>)\n",
            "Average Accuracy over Epoch: 61.03012814633291 %\n",
            "2 17501 Batch Validation Accuracy= 84.375 %\n",
            "2 17601 Batch Validation Accuracy= 71.875 %\n",
            "2 17701 Batch Validation Accuracy= 81.25 %\n",
            "2 17801 Batch Validation Accuracy= 71.875 %\n",
            "2 17901 Batch Validation Accuracy= 62.5 %\n",
            "2 18001 Batch Validation Accuracy= 75.0 %\n",
            "2 18101 Batch Validation Accuracy= 68.75 %\n",
            "2 18201 Batch Validation Accuracy= 75.0 %\n",
            "2 18301 Batch Validation Accuracy= 71.875 %\n",
            "2 18401 Batch Validation Accuracy= 68.75 %\n",
            "2 18501 Batch Validation Accuracy= 75.0 %\n",
            "2 18601 Batch Validation Accuracy= 84.375 %\n",
            "2 18701 Batch Validation Accuracy= 87.5 %\n",
            "2 18801 Batch Validation Accuracy= 81.25 %\n",
            "2 18901 Batch Validation Accuracy= 71.875 %\n",
            "2 19001 Batch Validation Accuracy= 75.0 %\n",
            "2 19101 Batch Validation Accuracy= 81.25 %\n",
            "2 19201 Batch Validation Accuracy= 81.25 %\n",
            "2 19301 Batch Validation Accuracy= 75.0 %\n",
            "2 19401 Batch Validation Accuracy= 71.875 %\n",
            "2 19501 Batch Validation Accuracy= 81.25 %\n",
            "2 19601 Batch Validation Accuracy= 84.375 %\n",
            "2 19701 Batch Validation Accuracy= 78.125 %\n",
            "2 19801 Batch Validation Accuracy= 68.75 %\n",
            "2 19901 Batch Validation Accuracy= 78.125 %\n",
            "2 20001 Batch Validation Accuracy= 71.875 %\n",
            "2 20101 Batch Validation Accuracy= 56.25 %\n",
            "2 20201 Batch Validation Accuracy= 68.75 %\n",
            "2 20301 Batch Validation Accuracy= 78.125 %\n",
            "2 20401 Batch Validation Accuracy= 71.875 %\n",
            "2 20501 Batch Validation Accuracy= 68.75 %\n",
            "2 20601 Batch Validation Accuracy= 78.125 %\n",
            "2 20701 Batch Validation Accuracy= 78.125 %\n",
            "2 20801 Batch Validation Accuracy= 81.25 %\n",
            "2 20901 Batch Validation Accuracy= 78.125 %\n",
            "2 21001 Batch Validation Accuracy= 78.125 %\n",
            "2 21101 Batch Validation Accuracy= 78.125 %\n",
            "2 21201 Batch Validation Accuracy= 75.0 %\n",
            "2 21301 Batch Validation Accuracy= 75.0 %\n",
            "2 21401 Batch Validation Accuracy= 75.0 %\n",
            "2 21501 Batch Validation Accuracy= 62.5 %\n",
            "2 21601 Batch Validation Accuracy= 81.25 %\n",
            "2 21701 Batch Validation Accuracy= 87.5 %\n",
            "2 21801 Batch Validation Accuracy= 84.375 %\n",
            "Average Validation Accuracy over Epoch= 76.93303951132802\n",
            "3 1 Batch Loss: tensor(0.9400, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.0012, grad_fn=<DivBackward0>)\n",
            "3 1001 Batch Loss: tensor(0.6259, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.7587, grad_fn=<DivBackward0>)\n",
            "3 2001 Batch Loss: tensor(0.8690, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.7411, grad_fn=<DivBackward0>)\n",
            "3 3001 Batch Loss: tensor(1.3359, grad_fn=<NllLossBackward>) Batch Accuracy= 62.5 % Average Loss Over 1000 Batches: tensor(0.7295, grad_fn=<DivBackward0>)\n",
            "3 4001 Batch Loss: tensor(1.0785, grad_fn=<NllLossBackward>) Batch Accuracy= 65.625 % Average Loss Over 1000 Batches: tensor(0.7309, grad_fn=<DivBackward0>)\n",
            "3 5001 Batch Loss: tensor(0.7521, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.7407, grad_fn=<DivBackward0>)\n",
            "3 6001 Batch Loss: tensor(0.5373, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.7098, grad_fn=<DivBackward0>)\n",
            "3 7001 Batch Loss: tensor(1.1262, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.7373, grad_fn=<DivBackward0>)\n",
            "3 8001 Batch Loss: tensor(0.9999, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.7247, grad_fn=<DivBackward0>)\n",
            "3 9001 Batch Loss: tensor(0.5631, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.7346, grad_fn=<DivBackward0>)\n",
            "3 10001 Batch Loss: tensor(0.4027, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.7239, grad_fn=<DivBackward0>)\n",
            "3 11001 Batch Loss: tensor(0.5179, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.7267, grad_fn=<DivBackward0>)\n",
            "3 12001 Batch Loss: tensor(1.1085, grad_fn=<NllLossBackward>) Batch Accuracy= 62.5 % Average Loss Over 1000 Batches: tensor(0.7165, grad_fn=<DivBackward0>)\n",
            "3 13001 Batch Loss: tensor(0.6249, grad_fn=<NllLossBackward>) Batch Accuracy= 90.625 % Average Loss Over 1000 Batches: tensor(0.7119, grad_fn=<DivBackward0>)\n",
            "3 14001 Batch Loss: tensor(0.5006, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.7142, grad_fn=<DivBackward0>)\n",
            "3 15001 Batch Loss: tensor(0.5259, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.7032, grad_fn=<DivBackward0>)\n",
            "3 16001 Batch Loss: tensor(0.7233, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.7040, grad_fn=<DivBackward0>)\n",
            "3 17001 Batch Loss: tensor(1.0044, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.7149, grad_fn=<DivBackward0>)\n",
            "Average Loss over Epoch: tensor(0.5814, grad_fn=<DivBackward0>)\n",
            "Average Accuracy over Epoch: 61.99838957405281 %\n",
            "3 17501 Batch Validation Accuracy= 71.875 %\n",
            "3 17601 Batch Validation Accuracy= 71.875 %\n",
            "3 17701 Batch Validation Accuracy= 75.0 %\n",
            "3 17801 Batch Validation Accuracy= 84.375 %\n",
            "3 17901 Batch Validation Accuracy= 78.125 %\n",
            "3 18001 Batch Validation Accuracy= 96.875 %\n",
            "3 18101 Batch Validation Accuracy= 90.625 %\n",
            "3 18201 Batch Validation Accuracy= 84.375 %\n",
            "3 18301 Batch Validation Accuracy= 71.875 %\n",
            "3 18401 Batch Validation Accuracy= 93.75 %\n",
            "3 18501 Batch Validation Accuracy= 84.375 %\n",
            "3 18601 Batch Validation Accuracy= 93.75 %\n",
            "3 18701 Batch Validation Accuracy= 84.375 %\n",
            "3 18801 Batch Validation Accuracy= 81.25 %\n",
            "3 18901 Batch Validation Accuracy= 65.625 %\n",
            "3 19001 Batch Validation Accuracy= 75.0 %\n",
            "3 19101 Batch Validation Accuracy= 75.0 %\n",
            "3 19201 Batch Validation Accuracy= 87.5 %\n",
            "3 19301 Batch Validation Accuracy= 71.875 %\n",
            "3 19401 Batch Validation Accuracy= 87.5 %\n",
            "3 19501 Batch Validation Accuracy= 71.875 %\n",
            "3 19601 Batch Validation Accuracy= 84.375 %\n",
            "3 19701 Batch Validation Accuracy= 87.5 %\n",
            "3 19801 Batch Validation Accuracy= 75.0 %\n",
            "3 19901 Batch Validation Accuracy= 75.0 %\n",
            "3 20001 Batch Validation Accuracy= 87.5 %\n",
            "3 20101 Batch Validation Accuracy= 75.0 %\n",
            "3 20201 Batch Validation Accuracy= 81.25 %\n",
            "3 20301 Batch Validation Accuracy= 81.25 %\n",
            "3 20401 Batch Validation Accuracy= 84.375 %\n",
            "3 20501 Batch Validation Accuracy= 71.875 %\n",
            "3 20601 Batch Validation Accuracy= 84.375 %\n",
            "3 20701 Batch Validation Accuracy= 71.875 %\n",
            "3 20801 Batch Validation Accuracy= 78.125 %\n",
            "3 20901 Batch Validation Accuracy= 84.375 %\n",
            "3 21001 Batch Validation Accuracy= 75.0 %\n",
            "3 21101 Batch Validation Accuracy= 84.375 %\n",
            "3 21201 Batch Validation Accuracy= 78.125 %\n",
            "3 21301 Batch Validation Accuracy= 81.25 %\n",
            "3 21401 Batch Validation Accuracy= 81.25 %\n",
            "3 21501 Batch Validation Accuracy= 81.25 %\n",
            "3 21601 Batch Validation Accuracy= 81.25 %\n",
            "3 21701 Batch Validation Accuracy= 81.25 %\n",
            "3 21801 Batch Validation Accuracy= 81.25 %\n",
            "Average Validation Accuracy over Epoch= 77.64778087064188\n",
            "4 1 Batch Loss: tensor(0.4498, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.0012, grad_fn=<DivBackward0>)\n",
            "4 1001 Batch Loss: tensor(0.6664, grad_fn=<NllLossBackward>) Batch Accuracy= 87.5 % Average Loss Over 1000 Batches: tensor(0.6899, grad_fn=<DivBackward0>)\n",
            "4 2001 Batch Loss: tensor(1.2828, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.7024, grad_fn=<DivBackward0>)\n",
            "4 3001 Batch Loss: tensor(0.6245, grad_fn=<NllLossBackward>) Batch Accuracy= 87.5 % Average Loss Over 1000 Batches: tensor(0.7031, grad_fn=<DivBackward0>)\n",
            "4 4001 Batch Loss: tensor(0.5197, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.7031, grad_fn=<DivBackward0>)\n",
            "4 5001 Batch Loss: tensor(0.5524, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.6911, grad_fn=<DivBackward0>)\n",
            "4 6001 Batch Loss: tensor(0.5476, grad_fn=<NllLossBackward>) Batch Accuracy= 90.625 % Average Loss Over 1000 Batches: tensor(0.6953, grad_fn=<DivBackward0>)\n",
            "4 7001 Batch Loss: tensor(0.6438, grad_fn=<NllLossBackward>) Batch Accuracy= 65.625 % Average Loss Over 1000 Batches: tensor(0.6975, grad_fn=<DivBackward0>)\n",
            "4 8001 Batch Loss: tensor(0.4492, grad_fn=<NllLossBackward>) Batch Accuracy= 87.5 % Average Loss Over 1000 Batches: tensor(0.6868, grad_fn=<DivBackward0>)\n",
            "4 9001 Batch Loss: tensor(0.9409, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.6796, grad_fn=<DivBackward0>)\n",
            "4 10001 Batch Loss: tensor(0.7601, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.7012, grad_fn=<DivBackward0>)\n",
            "4 11001 Batch Loss: tensor(0.9965, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.6784, grad_fn=<DivBackward0>)\n",
            "4 12001 Batch Loss: tensor(0.8279, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6796, grad_fn=<DivBackward0>)\n",
            "4 13001 Batch Loss: tensor(0.7301, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6821, grad_fn=<DivBackward0>)\n",
            "4 14001 Batch Loss: tensor(0.8742, grad_fn=<NllLossBackward>) Batch Accuracy= 65.625 % Average Loss Over 1000 Batches: tensor(0.6846, grad_fn=<DivBackward0>)\n",
            "4 15001 Batch Loss: tensor(0.5555, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.6880, grad_fn=<DivBackward0>)\n",
            "4 16001 Batch Loss: tensor(1.0638, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.6654, grad_fn=<DivBackward0>)\n",
            "4 17001 Batch Loss: tensor(0.2272, grad_fn=<NllLossBackward>) Batch Accuracy= 96.875 % Average Loss Over 1000 Batches: tensor(0.6737, grad_fn=<DivBackward0>)\n",
            "Average Loss over Epoch: tensor(0.5521, grad_fn=<DivBackward0>)\n",
            "Average Accuracy over Epoch: 62.629091971925206 %\n",
            "4 17501 Batch Validation Accuracy= 90.625 %\n",
            "4 17601 Batch Validation Accuracy= 81.25 %\n",
            "4 17701 Batch Validation Accuracy= 81.25 %\n",
            "4 17801 Batch Validation Accuracy= 84.375 %\n",
            "4 17901 Batch Validation Accuracy= 78.125 %\n",
            "4 18001 Batch Validation Accuracy= 84.375 %\n",
            "4 18101 Batch Validation Accuracy= 84.375 %\n",
            "4 18201 Batch Validation Accuracy= 81.25 %\n",
            "4 18301 Batch Validation Accuracy= 71.875 %\n",
            "4 18401 Batch Validation Accuracy= 78.125 %\n",
            "4 18501 Batch Validation Accuracy= 68.75 %\n",
            "4 18601 Batch Validation Accuracy= 78.125 %\n",
            "4 18701 Batch Validation Accuracy= 84.375 %\n",
            "4 18801 Batch Validation Accuracy= 90.625 %\n",
            "4 18901 Batch Validation Accuracy= 84.375 %\n",
            "4 19001 Batch Validation Accuracy= 81.25 %\n",
            "4 19101 Batch Validation Accuracy= 84.375 %\n",
            "4 19201 Batch Validation Accuracy= 71.875 %\n",
            "4 19301 Batch Validation Accuracy= 87.5 %\n",
            "4 19401 Batch Validation Accuracy= 84.375 %\n",
            "4 19501 Batch Validation Accuracy= 81.25 %\n",
            "4 19601 Batch Validation Accuracy= 78.125 %\n",
            "4 19701 Batch Validation Accuracy= 75.0 %\n",
            "4 19801 Batch Validation Accuracy= 78.125 %\n",
            "4 19901 Batch Validation Accuracy= 81.25 %\n",
            "4 20001 Batch Validation Accuracy= 81.25 %\n",
            "4 20101 Batch Validation Accuracy= 87.5 %\n",
            "4 20201 Batch Validation Accuracy= 75.0 %\n",
            "4 20301 Batch Validation Accuracy= 81.25 %\n",
            "4 20401 Batch Validation Accuracy= 78.125 %\n",
            "4 20501 Batch Validation Accuracy= 68.75 %\n",
            "4 20601 Batch Validation Accuracy= 78.125 %\n",
            "4 20701 Batch Validation Accuracy= 87.5 %\n",
            "4 20801 Batch Validation Accuracy= 68.75 %\n",
            "4 20901 Batch Validation Accuracy= 65.625 %\n",
            "4 21001 Batch Validation Accuracy= 84.375 %\n",
            "4 21101 Batch Validation Accuracy= 84.375 %\n",
            "4 21201 Batch Validation Accuracy= 84.375 %\n",
            "4 21301 Batch Validation Accuracy= 75.0 %\n",
            "4 21401 Batch Validation Accuracy= 87.5 %\n",
            "4 21501 Batch Validation Accuracy= 75.0 %\n",
            "4 21601 Batch Validation Accuracy= 87.5 %\n",
            "4 21701 Batch Validation Accuracy= 75.0 %\n",
            "4 21801 Batch Validation Accuracy= 75.0 %\n",
            "Average Validation Accuracy over Epoch= 78.95330743060491\n",
            "5 1 Batch Loss: tensor(0.9029, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.0019, grad_fn=<DivBackward0>)\n",
            "5 1001 Batch Loss: tensor(1.2631, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.6612, grad_fn=<DivBackward0>)\n",
            "5 2001 Batch Loss: tensor(0.3787, grad_fn=<NllLossBackward>) Batch Accuracy= 90.625 % Average Loss Over 1000 Batches: tensor(0.6624, grad_fn=<DivBackward0>)\n",
            "5 3001 Batch Loss: tensor(0.8105, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.6593, grad_fn=<DivBackward0>)\n",
            "5 4001 Batch Loss: tensor(0.8927, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.6563, grad_fn=<DivBackward0>)\n",
            "5 5001 Batch Loss: tensor(1.0038, grad_fn=<NllLossBackward>) Batch Accuracy= 87.5 % Average Loss Over 1000 Batches: tensor(0.6676, grad_fn=<DivBackward0>)\n",
            "5 6001 Batch Loss: tensor(1.3657, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.6758, grad_fn=<DivBackward0>)\n",
            "5 7001 Batch Loss: tensor(0.6088, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.6757, grad_fn=<DivBackward0>)\n",
            "5 8001 Batch Loss: tensor(1.2757, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.6596, grad_fn=<DivBackward0>)\n",
            "5 9001 Batch Loss: tensor(1.1762, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.6535, grad_fn=<DivBackward0>)\n",
            "5 10001 Batch Loss: tensor(0.7144, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6657, grad_fn=<DivBackward0>)\n",
            "5 11001 Batch Loss: tensor(1.3126, grad_fn=<NllLossBackward>) Batch Accuracy= 62.5 % Average Loss Over 1000 Batches: tensor(0.6586, grad_fn=<DivBackward0>)\n",
            "5 12001 Batch Loss: tensor(0.8138, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.6545, grad_fn=<DivBackward0>)\n",
            "5 13001 Batch Loss: tensor(0.7008, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.6625, grad_fn=<DivBackward0>)\n",
            "5 14001 Batch Loss: tensor(0.4373, grad_fn=<NllLossBackward>) Batch Accuracy= 87.5 % Average Loss Over 1000 Batches: tensor(0.6488, grad_fn=<DivBackward0>)\n",
            "5 15001 Batch Loss: tensor(0.5637, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6496, grad_fn=<DivBackward0>)\n",
            "5 16001 Batch Loss: tensor(0.4077, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.6597, grad_fn=<DivBackward0>)\n",
            "5 17001 Batch Loss: tensor(0.6553, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6438, grad_fn=<DivBackward0>)\n",
            "Average Loss over Epoch: tensor(0.5290, grad_fn=<DivBackward0>)\n",
            "Average Accuracy over Epoch: 63.14517330703163 %\n",
            "5 17501 Batch Validation Accuracy= 81.25 %\n",
            "5 17601 Batch Validation Accuracy= 78.125 %\n",
            "5 17701 Batch Validation Accuracy= 65.625 %\n",
            "5 17801 Batch Validation Accuracy= 71.875 %\n",
            "5 17901 Batch Validation Accuracy= 84.375 %\n",
            "5 18001 Batch Validation Accuracy= 71.875 %\n",
            "5 18101 Batch Validation Accuracy= 75.0 %\n",
            "5 18201 Batch Validation Accuracy= 78.125 %\n",
            "5 18301 Batch Validation Accuracy= 62.5 %\n",
            "5 18401 Batch Validation Accuracy= 78.125 %\n",
            "5 18501 Batch Validation Accuracy= 65.625 %\n",
            "5 18601 Batch Validation Accuracy= 81.25 %\n",
            "5 18701 Batch Validation Accuracy= 87.5 %\n",
            "5 18801 Batch Validation Accuracy= 81.25 %\n",
            "5 18901 Batch Validation Accuracy= 71.875 %\n",
            "5 19001 Batch Validation Accuracy= 90.625 %\n",
            "5 19101 Batch Validation Accuracy= 93.75 %\n",
            "5 19201 Batch Validation Accuracy= 81.25 %\n",
            "5 19301 Batch Validation Accuracy= 75.0 %\n",
            "5 19401 Batch Validation Accuracy= 71.875 %\n",
            "5 19501 Batch Validation Accuracy= 87.5 %\n",
            "5 19601 Batch Validation Accuracy= 81.25 %\n",
            "5 19701 Batch Validation Accuracy= 71.875 %\n",
            "5 19801 Batch Validation Accuracy= 81.25 %\n",
            "5 19901 Batch Validation Accuracy= 75.0 %\n",
            "5 20001 Batch Validation Accuracy= 78.125 %\n",
            "5 20101 Batch Validation Accuracy= 87.5 %\n",
            "5 20201 Batch Validation Accuracy= 84.375 %\n",
            "5 20301 Batch Validation Accuracy= 87.5 %\n",
            "5 20401 Batch Validation Accuracy= 81.25 %\n",
            "5 20501 Batch Validation Accuracy= 90.625 %\n",
            "5 20601 Batch Validation Accuracy= 81.25 %\n",
            "5 20701 Batch Validation Accuracy= 62.5 %\n",
            "5 20801 Batch Validation Accuracy= 81.25 %\n",
            "5 20901 Batch Validation Accuracy= 75.0 %\n",
            "5 21001 Batch Validation Accuracy= 81.25 %\n",
            "5 21101 Batch Validation Accuracy= 78.125 %\n",
            "5 21201 Batch Validation Accuracy= 78.125 %\n",
            "5 21301 Batch Validation Accuracy= 87.5 %\n",
            "5 21401 Batch Validation Accuracy= 84.375 %\n",
            "5 21501 Batch Validation Accuracy= 84.375 %\n",
            "5 21601 Batch Validation Accuracy= 71.875 %\n",
            "5 21701 Batch Validation Accuracy= 87.5 %\n",
            "5 21801 Batch Validation Accuracy= 84.375 %\n",
            "Average Validation Accuracy over Epoch= 78.76942704708964\n",
            "6 1 Batch Loss: tensor(0.4255, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.0013, grad_fn=<DivBackward0>)\n",
            "6 1001 Batch Loss: tensor(0.5145, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6434, grad_fn=<DivBackward0>)\n",
            "6 2001 Batch Loss: tensor(0.7216, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.6355, grad_fn=<DivBackward0>)\n",
            "6 3001 Batch Loss: tensor(0.4693, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.6361, grad_fn=<DivBackward0>)\n",
            "6 4001 Batch Loss: tensor(0.2597, grad_fn=<NllLossBackward>) Batch Accuracy= 90.625 % Average Loss Over 1000 Batches: tensor(0.6555, grad_fn=<DivBackward0>)\n",
            "6 5001 Batch Loss: tensor(0.6125, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.6410, grad_fn=<DivBackward0>)\n",
            "6 6001 Batch Loss: tensor(0.5269, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.6421, grad_fn=<DivBackward0>)\n",
            "6 7001 Batch Loss: tensor(1.5224, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.6352, grad_fn=<DivBackward0>)\n",
            "6 8001 Batch Loss: tensor(0.6673, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.6594, grad_fn=<DivBackward0>)\n",
            "6 9001 Batch Loss: tensor(0.7471, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6429, grad_fn=<DivBackward0>)\n",
            "6 10001 Batch Loss: tensor(0.4461, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6153, grad_fn=<DivBackward0>)\n",
            "6 11001 Batch Loss: tensor(0.6083, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.6390, grad_fn=<DivBackward0>)\n",
            "6 12001 Batch Loss: tensor(0.4968, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.6336, grad_fn=<DivBackward0>)\n",
            "6 13001 Batch Loss: tensor(0.9619, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6401, grad_fn=<DivBackward0>)\n",
            "6 14001 Batch Loss: tensor(0.5385, grad_fn=<NllLossBackward>) Batch Accuracy= 87.5 % Average Loss Over 1000 Batches: tensor(0.6334, grad_fn=<DivBackward0>)\n",
            "6 15001 Batch Loss: tensor(0.2990, grad_fn=<NllLossBackward>) Batch Accuracy= 90.625 % Average Loss Over 1000 Batches: tensor(0.6392, grad_fn=<DivBackward0>)\n",
            "6 16001 Batch Loss: tensor(0.3540, grad_fn=<NllLossBackward>) Batch Accuracy= 90.625 % Average Loss Over 1000 Batches: tensor(0.6308, grad_fn=<DivBackward0>)\n",
            "6 17001 Batch Loss: tensor(0.6241, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.6368, grad_fn=<DivBackward0>)\n",
            "Average Loss over Epoch: tensor(0.5128, grad_fn=<DivBackward0>)\n",
            "Average Accuracy over Epoch: 63.50092843059306 %\n",
            "6 17501 Batch Validation Accuracy= 68.75 %\n",
            "6 17601 Batch Validation Accuracy= 84.375 %\n",
            "6 17701 Batch Validation Accuracy= 81.25 %\n",
            "6 17801 Batch Validation Accuracy= 78.125 %\n",
            "6 17901 Batch Validation Accuracy= 84.375 %\n",
            "6 18001 Batch Validation Accuracy= 87.5 %\n",
            "6 18101 Batch Validation Accuracy= 84.375 %\n",
            "6 18201 Batch Validation Accuracy= 84.375 %\n",
            "6 18301 Batch Validation Accuracy= 75.0 %\n",
            "6 18401 Batch Validation Accuracy= 81.25 %\n",
            "6 18501 Batch Validation Accuracy= 71.875 %\n",
            "6 18601 Batch Validation Accuracy= 78.125 %\n",
            "6 18701 Batch Validation Accuracy= 84.375 %\n",
            "6 18801 Batch Validation Accuracy= 75.0 %\n",
            "6 18901 Batch Validation Accuracy= 84.375 %\n",
            "6 19001 Batch Validation Accuracy= 81.25 %\n",
            "6 19101 Batch Validation Accuracy= 81.25 %\n",
            "6 19201 Batch Validation Accuracy= 71.875 %\n",
            "6 19301 Batch Validation Accuracy= 78.125 %\n",
            "6 19401 Batch Validation Accuracy= 90.625 %\n",
            "6 19501 Batch Validation Accuracy= 78.125 %\n",
            "6 19601 Batch Validation Accuracy= 84.375 %\n",
            "6 19701 Batch Validation Accuracy= 78.125 %\n",
            "6 19801 Batch Validation Accuracy= 78.125 %\n",
            "6 19901 Batch Validation Accuracy= 84.375 %\n",
            "6 20001 Batch Validation Accuracy= 84.375 %\n",
            "6 20101 Batch Validation Accuracy= 68.75 %\n",
            "6 20201 Batch Validation Accuracy= 71.875 %\n",
            "6 20301 Batch Validation Accuracy= 59.375 %\n",
            "6 20401 Batch Validation Accuracy= 84.375 %\n",
            "6 20501 Batch Validation Accuracy= 84.375 %\n",
            "6 20601 Batch Validation Accuracy= 75.0 %\n",
            "6 20701 Batch Validation Accuracy= 84.375 %\n",
            "6 20801 Batch Validation Accuracy= 68.75 %\n",
            "6 20901 Batch Validation Accuracy= 71.875 %\n",
            "6 21001 Batch Validation Accuracy= 90.625 %\n",
            "6 21101 Batch Validation Accuracy= 78.125 %\n",
            "6 21201 Batch Validation Accuracy= 90.625 %\n",
            "6 21301 Batch Validation Accuracy= 87.5 %\n",
            "6 21401 Batch Validation Accuracy= 75.0 %\n",
            "6 21501 Batch Validation Accuracy= 90.625 %\n",
            "6 21601 Batch Validation Accuracy= 68.75 %\n",
            "6 21701 Batch Validation Accuracy= 84.375 %\n",
            "6 21801 Batch Validation Accuracy= 65.625 %\n",
            "Average Validation Accuracy over Epoch= 79.55689901801705\n",
            "7 1 Batch Loss: tensor(0.3992, grad_fn=<NllLossBackward>) Batch Accuracy= 90.625 % Average Loss Over 1000 Batches: tensor(0.0009, grad_fn=<DivBackward0>)\n",
            "7 1001 Batch Loss: tensor(0.6322, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.6410, grad_fn=<DivBackward0>)\n",
            "7 2001 Batch Loss: tensor(0.3071, grad_fn=<NllLossBackward>) Batch Accuracy= 87.5 % Average Loss Over 1000 Batches: tensor(0.6215, grad_fn=<DivBackward0>)\n",
            "7 3001 Batch Loss: tensor(0.5622, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.6280, grad_fn=<DivBackward0>)\n",
            "7 4001 Batch Loss: tensor(0.9182, grad_fn=<NllLossBackward>) Batch Accuracy= 90.625 % Average Loss Over 1000 Batches: tensor(0.6066, grad_fn=<DivBackward0>)\n",
            "7 5001 Batch Loss: tensor(1.5037, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.6116, grad_fn=<DivBackward0>)\n",
            "7 6001 Batch Loss: tensor(0.4727, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.6200, grad_fn=<DivBackward0>)\n",
            "7 7001 Batch Loss: tensor(0.4068, grad_fn=<NllLossBackward>) Batch Accuracy= 87.5 % Average Loss Over 1000 Batches: tensor(0.6311, grad_fn=<DivBackward0>)\n",
            "7 8001 Batch Loss: tensor(0.3872, grad_fn=<NllLossBackward>) Batch Accuracy= 90.625 % Average Loss Over 1000 Batches: tensor(0.6237, grad_fn=<DivBackward0>)\n",
            "7 9001 Batch Loss: tensor(0.2468, grad_fn=<NllLossBackward>) Batch Accuracy= 100.0 % Average Loss Over 1000 Batches: tensor(0.6337, grad_fn=<DivBackward0>)\n",
            "7 10001 Batch Loss: tensor(0.5362, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.6240, grad_fn=<DivBackward0>)\n",
            "7 11001 Batch Loss: tensor(0.7967, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.6172, grad_fn=<DivBackward0>)\n",
            "7 12001 Batch Loss: tensor(0.7129, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6171, grad_fn=<DivBackward0>)\n",
            "7 13001 Batch Loss: tensor(0.3134, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.6194, grad_fn=<DivBackward0>)\n",
            "7 14001 Batch Loss: tensor(1.1615, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.6249, grad_fn=<DivBackward0>)\n",
            "7 15001 Batch Loss: tensor(0.3776, grad_fn=<NllLossBackward>) Batch Accuracy= 87.5 % Average Loss Over 1000 Batches: tensor(0.6200, grad_fn=<DivBackward0>)\n",
            "7 16001 Batch Loss: tensor(1.3430, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.6194, grad_fn=<DivBackward0>)\n",
            "7 17001 Batch Loss: tensor(0.4151, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.6253, grad_fn=<DivBackward0>)\n",
            "Average Loss over Epoch: tensor(0.4993, grad_fn=<DivBackward0>)\n",
            "Average Accuracy over Epoch: 63.76541653292685 %\n",
            "7 17501 Batch Validation Accuracy= 81.25 %\n",
            "7 17601 Batch Validation Accuracy= 81.25 %\n",
            "7 17701 Batch Validation Accuracy= 81.25 %\n",
            "7 17801 Batch Validation Accuracy= 84.375 %\n",
            "7 17901 Batch Validation Accuracy= 81.25 %\n",
            "7 18001 Batch Validation Accuracy= 68.75 %\n",
            "7 18101 Batch Validation Accuracy= 65.625 %\n",
            "7 18201 Batch Validation Accuracy= 87.5 %\n",
            "7 18301 Batch Validation Accuracy= 84.375 %\n",
            "7 18401 Batch Validation Accuracy= 84.375 %\n",
            "7 18501 Batch Validation Accuracy= 75.0 %\n",
            "7 18601 Batch Validation Accuracy= 90.625 %\n",
            "7 18701 Batch Validation Accuracy= 78.125 %\n",
            "7 18801 Batch Validation Accuracy= 84.375 %\n",
            "7 18901 Batch Validation Accuracy= 68.75 %\n",
            "7 19001 Batch Validation Accuracy= 84.375 %\n",
            "7 19101 Batch Validation Accuracy= 84.375 %\n",
            "7 19201 Batch Validation Accuracy= 75.0 %\n",
            "7 19301 Batch Validation Accuracy= 87.5 %\n",
            "7 19401 Batch Validation Accuracy= 87.5 %\n",
            "7 19501 Batch Validation Accuracy= 84.375 %\n",
            "7 19601 Batch Validation Accuracy= 78.125 %\n",
            "7 19701 Batch Validation Accuracy= 75.0 %\n",
            "7 19801 Batch Validation Accuracy= 84.375 %\n",
            "7 19901 Batch Validation Accuracy= 78.125 %\n",
            "7 20001 Batch Validation Accuracy= 81.25 %\n",
            "7 20101 Batch Validation Accuracy= 78.125 %\n",
            "7 20201 Batch Validation Accuracy= 96.875 %\n",
            "7 20301 Batch Validation Accuracy= 84.375 %\n",
            "7 20401 Batch Validation Accuracy= 75.0 %\n",
            "7 20501 Batch Validation Accuracy= 81.25 %\n",
            "7 20601 Batch Validation Accuracy= 87.5 %\n",
            "7 20701 Batch Validation Accuracy= 78.125 %\n",
            "7 20801 Batch Validation Accuracy= 96.875 %\n",
            "7 20901 Batch Validation Accuracy= 78.125 %\n",
            "7 21001 Batch Validation Accuracy= 90.625 %\n",
            "7 21101 Batch Validation Accuracy= 84.375 %\n",
            "7 21201 Batch Validation Accuracy= 87.5 %\n",
            "7 21301 Batch Validation Accuracy= 78.125 %\n",
            "7 21401 Batch Validation Accuracy= 75.0 %\n",
            "7 21501 Batch Validation Accuracy= 78.125 %\n",
            "7 21601 Batch Validation Accuracy= 81.25 %\n",
            "7 21701 Batch Validation Accuracy= 75.0 %\n",
            "7 21801 Batch Validation Accuracy= 87.5 %\n",
            "Average Validation Accuracy over Epoch= 80.2895209928102\n",
            "8 1 Batch Loss: tensor(0.5533, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.0009, grad_fn=<DivBackward0>)\n",
            "8 1001 Batch Loss: tensor(0.5957, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.5964, grad_fn=<DivBackward0>)\n",
            "8 2001 Batch Loss: tensor(0.8245, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6166, grad_fn=<DivBackward0>)\n",
            "8 3001 Batch Loss: tensor(0.4381, grad_fn=<NllLossBackward>) Batch Accuracy= 90.625 % Average Loss Over 1000 Batches: tensor(0.6042, grad_fn=<DivBackward0>)\n",
            "8 4001 Batch Loss: tensor(0.6757, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.6207, grad_fn=<DivBackward0>)\n",
            "8 5001 Batch Loss: tensor(0.4179, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.6114, grad_fn=<DivBackward0>)\n",
            "8 6001 Batch Loss: tensor(0.6508, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6065, grad_fn=<DivBackward0>)\n",
            "8 7001 Batch Loss: tensor(0.4544, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6025, grad_fn=<DivBackward0>)\n",
            "8 8001 Batch Loss: tensor(0.4978, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6034, grad_fn=<DivBackward0>)\n",
            "8 9001 Batch Loss: tensor(0.6712, grad_fn=<NllLossBackward>) Batch Accuracy= 68.75 % Average Loss Over 1000 Batches: tensor(0.6103, grad_fn=<DivBackward0>)\n",
            "8 10001 Batch Loss: tensor(0.4924, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.6233, grad_fn=<DivBackward0>)\n",
            "8 11001 Batch Loss: tensor(0.1806, grad_fn=<NllLossBackward>) Batch Accuracy= 96.875 % Average Loss Over 1000 Batches: tensor(0.5998, grad_fn=<DivBackward0>)\n",
            "8 12001 Batch Loss: tensor(0.4218, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.6045, grad_fn=<DivBackward0>)\n",
            "8 13001 Batch Loss: tensor(0.4445, grad_fn=<NllLossBackward>) Batch Accuracy= 90.625 % Average Loss Over 1000 Batches: tensor(0.5970, grad_fn=<DivBackward0>)\n",
            "8 14001 Batch Loss: tensor(0.3926, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.6052, grad_fn=<DivBackward0>)\n",
            "8 15001 Batch Loss: tensor(0.8585, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.5995, grad_fn=<DivBackward0>)\n",
            "8 16001 Batch Loss: tensor(0.4887, grad_fn=<NllLossBackward>) Batch Accuracy= 81.25 % Average Loss Over 1000 Batches: tensor(0.6281, grad_fn=<DivBackward0>)\n",
            "8 17001 Batch Loss: tensor(0.5297, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.5980, grad_fn=<DivBackward0>)\n",
            "Average Loss over Epoch: tensor(0.4875, grad_fn=<DivBackward0>)\n",
            "Average Accuracy over Epoch: 64.06715648065976 %\n",
            "8 17501 Batch Validation Accuracy= 62.5 %\n",
            "8 17601 Batch Validation Accuracy= 90.625 %\n",
            "8 17701 Batch Validation Accuracy= 87.5 %\n",
            "8 17801 Batch Validation Accuracy= 78.125 %\n",
            "8 17901 Batch Validation Accuracy= 65.625 %\n",
            "8 18001 Batch Validation Accuracy= 90.625 %\n",
            "8 18101 Batch Validation Accuracy= 78.125 %\n",
            "8 18201 Batch Validation Accuracy= 68.75 %\n",
            "8 18301 Batch Validation Accuracy= 75.0 %\n",
            "8 18401 Batch Validation Accuracy= 78.125 %\n",
            "8 18501 Batch Validation Accuracy= 71.875 %\n",
            "8 18601 Batch Validation Accuracy= 71.875 %\n",
            "8 18701 Batch Validation Accuracy= 65.625 %\n",
            "8 18801 Batch Validation Accuracy= 65.625 %\n",
            "8 18901 Batch Validation Accuracy= 75.0 %\n",
            "8 19001 Batch Validation Accuracy= 71.875 %\n",
            "8 19101 Batch Validation Accuracy= 87.5 %\n",
            "8 19201 Batch Validation Accuracy= 65.625 %\n",
            "8 19301 Batch Validation Accuracy= 81.25 %\n",
            "8 19401 Batch Validation Accuracy= 87.5 %\n",
            "8 19501 Batch Validation Accuracy= 81.25 %\n",
            "8 19601 Batch Validation Accuracy= 78.125 %\n",
            "8 19701 Batch Validation Accuracy= 75.0 %\n",
            "8 19801 Batch Validation Accuracy= 84.375 %\n",
            "8 19901 Batch Validation Accuracy= 81.25 %\n",
            "8 20001 Batch Validation Accuracy= 84.375 %\n",
            "8 20101 Batch Validation Accuracy= 81.25 %\n",
            "8 20201 Batch Validation Accuracy= 90.625 %\n",
            "8 20301 Batch Validation Accuracy= 78.125 %\n",
            "8 20401 Batch Validation Accuracy= 62.5 %\n",
            "8 20501 Batch Validation Accuracy= 68.75 %\n",
            "8 20601 Batch Validation Accuracy= 62.5 %\n",
            "8 20701 Batch Validation Accuracy= 84.375 %\n",
            "8 20801 Batch Validation Accuracy= 84.375 %\n",
            "8 20901 Batch Validation Accuracy= 78.125 %\n",
            "8 21001 Batch Validation Accuracy= 78.125 %\n",
            "8 21101 Batch Validation Accuracy= 81.25 %\n",
            "8 21201 Batch Validation Accuracy= 81.25 %\n",
            "8 21301 Batch Validation Accuracy= 78.125 %\n",
            "8 21401 Batch Validation Accuracy= 78.125 %\n",
            "8 21501 Batch Validation Accuracy= 81.25 %\n",
            "8 21601 Batch Validation Accuracy= 68.75 %\n",
            "8 21701 Batch Validation Accuracy= 75.0 %\n",
            "8 21801 Batch Validation Accuracy= 87.5 %\n",
            "Average Validation Accuracy over Epoch= 79.21813384365682\n",
            "9 1 Batch Loss: tensor(0.6280, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.0010, grad_fn=<DivBackward0>)\n",
            "9 1001 Batch Loss: tensor(0.3995, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.5879, grad_fn=<DivBackward0>)\n",
            "9 2001 Batch Loss: tensor(0.8701, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.6040, grad_fn=<DivBackward0>)\n",
            "9 3001 Batch Loss: tensor(0.1638, grad_fn=<NllLossBackward>) Batch Accuracy= 93.75 % Average Loss Over 1000 Batches: tensor(0.5970, grad_fn=<DivBackward0>)\n",
            "9 4001 Batch Loss: tensor(0.2606, grad_fn=<NllLossBackward>) Batch Accuracy= 93.75 % Average Loss Over 1000 Batches: tensor(0.6054, grad_fn=<DivBackward0>)\n",
            "9 5001 Batch Loss: tensor(0.5819, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.6056, grad_fn=<DivBackward0>)\n",
            "9 6001 Batch Loss: tensor(0.3441, grad_fn=<NllLossBackward>) Batch Accuracy= 93.75 % Average Loss Over 1000 Batches: tensor(0.6024, grad_fn=<DivBackward0>)\n",
            "9 7001 Batch Loss: tensor(0.6182, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.5955, grad_fn=<DivBackward0>)\n",
            "9 8001 Batch Loss: tensor(0.9129, grad_fn=<NllLossBackward>) Batch Accuracy= 78.125 % Average Loss Over 1000 Batches: tensor(0.5924, grad_fn=<DivBackward0>)\n",
            "9 9001 Batch Loss: tensor(0.7461, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.5971, grad_fn=<DivBackward0>)\n",
            "9 10001 Batch Loss: tensor(0.5096, grad_fn=<NllLossBackward>) Batch Accuracy= 71.875 % Average Loss Over 1000 Batches: tensor(0.5957, grad_fn=<DivBackward0>)\n",
            "9 11001 Batch Loss: tensor(0.5134, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.5926, grad_fn=<DivBackward0>)\n",
            "9 12001 Batch Loss: tensor(0.4931, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.5924, grad_fn=<DivBackward0>)\n",
            "9 13001 Batch Loss: tensor(0.3370, grad_fn=<NllLossBackward>) Batch Accuracy= 75.0 % Average Loss Over 1000 Batches: tensor(0.5944, grad_fn=<DivBackward0>)\n",
            "9 14001 Batch Loss: tensor(0.6451, grad_fn=<NllLossBackward>) Batch Accuracy= 68.75 % Average Loss Over 1000 Batches: tensor(0.5853, grad_fn=<DivBackward0>)\n",
            "9 15001 Batch Loss: tensor(0.2377, grad_fn=<NllLossBackward>) Batch Accuracy= 90.625 % Average Loss Over 1000 Batches: tensor(0.5961, grad_fn=<DivBackward0>)\n",
            "9 16001 Batch Loss: tensor(0.4573, grad_fn=<NllLossBackward>) Batch Accuracy= 87.5 % Average Loss Over 1000 Batches: tensor(0.5920, grad_fn=<DivBackward0>)\n",
            "9 17001 Batch Loss: tensor(0.3351, grad_fn=<NllLossBackward>) Batch Accuracy= 84.375 % Average Loss Over 1000 Batches: tensor(0.5915, grad_fn=<DivBackward0>)\n",
            "Average Loss over Epoch: tensor(0.4780, grad_fn=<DivBackward0>)\n",
            "Average Accuracy over Epoch: 64.20900004583375 %\n",
            "9 17501 Batch Validation Accuracy= 75.0 %\n",
            "9 17601 Batch Validation Accuracy= 78.125 %\n",
            "9 17701 Batch Validation Accuracy= 65.625 %\n",
            "9 17801 Batch Validation Accuracy= 75.0 %\n",
            "9 17901 Batch Validation Accuracy= 78.125 %\n",
            "9 18001 Batch Validation Accuracy= 81.25 %\n",
            "9 18101 Batch Validation Accuracy= 75.0 %\n",
            "9 18201 Batch Validation Accuracy= 71.875 %\n",
            "9 18301 Batch Validation Accuracy= 81.25 %\n",
            "9 18401 Batch Validation Accuracy= 84.375 %\n",
            "9 18501 Batch Validation Accuracy= 84.375 %\n",
            "9 18601 Batch Validation Accuracy= 96.875 %\n",
            "9 18701 Batch Validation Accuracy= 81.25 %\n",
            "9 18801 Batch Validation Accuracy= 87.5 %\n",
            "9 18901 Batch Validation Accuracy= 62.5 %\n",
            "9 19001 Batch Validation Accuracy= 78.125 %\n",
            "9 19101 Batch Validation Accuracy= 78.125 %\n",
            "9 19201 Batch Validation Accuracy= 71.875 %\n",
            "9 19301 Batch Validation Accuracy= 71.875 %\n",
            "9 19401 Batch Validation Accuracy= 81.25 %\n",
            "9 19501 Batch Validation Accuracy= 87.5 %\n",
            "9 19601 Batch Validation Accuracy= 90.625 %\n",
            "9 19701 Batch Validation Accuracy= 75.0 %\n",
            "9 19801 Batch Validation Accuracy= 87.5 %\n",
            "9 19901 Batch Validation Accuracy= 71.875 %\n",
            "9 20001 Batch Validation Accuracy= 71.875 %\n",
            "9 20101 Batch Validation Accuracy= 87.5 %\n",
            "9 20201 Batch Validation Accuracy= 78.125 %\n",
            "9 20301 Batch Validation Accuracy= 84.375 %\n",
            "9 20401 Batch Validation Accuracy= 90.625 %\n",
            "9 20501 Batch Validation Accuracy= 81.25 %\n",
            "9 20601 Batch Validation Accuracy= 84.375 %\n",
            "9 20701 Batch Validation Accuracy= 84.375 %\n",
            "9 20801 Batch Validation Accuracy= 75.0 %\n",
            "9 20901 Batch Validation Accuracy= 71.875 %\n",
            "9 21001 Batch Validation Accuracy= 71.875 %\n",
            "9 21101 Batch Validation Accuracy= 87.5 %\n",
            "9 21201 Batch Validation Accuracy= 65.625 %\n",
            "9 21301 Batch Validation Accuracy= 75.0 %\n",
            "9 21401 Batch Validation Accuracy= 81.25 %\n",
            "9 21501 Batch Validation Accuracy= 71.875 %\n",
            "9 21601 Batch Validation Accuracy= 78.125 %\n",
            "9 21701 Batch Validation Accuracy= 78.125 %\n",
            "9 21801 Batch Validation Accuracy= 84.375 %\n",
            "Average Validation Accuracy over Epoch= 80.77157272094776\n",
            "hopefully i reach this part of the function\n",
            "[52.014321901782026, 59.48618243086869, 61.03012814633291, 61.99838957405281, 62.629091971925206, 63.14517330703163, 63.50092843059306, 63.76541653292685, 64.06715648065976, 64.20900004583375]\n",
            "[tensor(1.2302, grad_fn=<DivBackward0>), tensor(0.7196, grad_fn=<DivBackward0>), tensor(0.6291, grad_fn=<DivBackward0>), tensor(0.5814, grad_fn=<DivBackward0>), tensor(0.5521, grad_fn=<DivBackward0>), tensor(0.5290, grad_fn=<DivBackward0>), tensor(0.5128, grad_fn=<DivBackward0>), tensor(0.4993, grad_fn=<DivBackward0>), tensor(0.4875, grad_fn=<DivBackward0>), tensor(0.4780, grad_fn=<DivBackward0>)]\n",
            "[71.7781063944944, 75.19982795948391, 76.93303951132802, 77.64778087064188, 78.95330743060491, 78.76942704708964, 79.55689901801705, 80.2895209928102, 79.21813384365682, 80.77157272094776]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RNK77V_NXfy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "be76f2e5-3d35-41b6-8b4a-5b76fa4c33af"
      },
      "source": [
        "accvepochs=[52.014321901782026, 59.48618243086869, 61.03012814633291, 61.99838957405281, 62.629091971925206, 63.14517330703163, 63.50092843059306, 63.76541653292685, 64.06715648065976, 64.20900004583375]\n",
        "validationaccvepochs=[71.7781063944944, 75.19982795948391, 76.93303951132802, 77.64778087064188, 78.95330743060491, 78.76942704708964, 79.55689901801705, 80.2895209928102, 79.21813384365682, 80.77157272094776]\n",
        "plt.plot([1,2,3,4,5,6,7,8,9,10],accvepochs,'rs')\n",
        "plt.plot([1,2,3,4,5,6,7,8,9,10],validationaccvepochs,'bo')\n",
        "plt.plot([1,2,3,4,5,6,7,8,9,10],accvepochs,label='Train accuracy')\n",
        "plt.plot([1,2,3,4,5,6,7,8,9,10],validationaccvepochs,label='Validation accuracy')\n",
        "plt.axis([0,12,45,95])\n",
        "plt.xlabel('Number of Epochs of training completed')\n",
        "plt.ylabel('Accuracy(%)')\n",
        "plt.legend()\n",
        "plt.title('Train and Validation accuracy vs. Epochs')\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zADKdITqWoPE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5739047d-63a2-49ae-a251-03766a03a082"
      },
      "source": [
        "lossperepoch=[1.2302,0.7196,0.6291,0.5814,0.5521,0.5290,0.5128,0.4993,0.4875,0.4780,]\n",
        "#print(lossperepoch)\n",
        "plt.plot([1,2,3,4,5,6,7,8,9,10], lossperepoch, 'y^')\n",
        "plt.plot([1,2,3,4,5,6,7,8,9,10], lossperepoch)\n",
        "plt.xlabel('Number of Epochs of training completed')\n",
        "plt.ylabel('Average Cross Entropy (Weighted) Loss')\n",
        "plt.axis([0,12,0,1.3])\n",
        "plt.title('Average Cross Entropy (Weighted) Training Loss vs. Epochs')\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
